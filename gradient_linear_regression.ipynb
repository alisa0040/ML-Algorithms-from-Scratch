{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Q0OFUOI7Uzv3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0.3,0.7,1.1],[0.09, 0.49, 1.21]])\n",
        "y = np.array([2.2,3.1,0.6])\n",
        "w = np.array([0.5,0.5,0.5])\n",
        "dw = np.zeros(w.shape)\n",
        "\n",
        "def gradient_descent(X, y, w, learn_rate, epochs):\n",
        "  m = X.shape[1]\n",
        "  for i in range(epochs):\n",
        "    y_pred = w[0]+ w[1] * X[0] + w[2] * X[1]\n",
        "    error = y_pred - y\n",
        "    dw[0] = sum(error) * (1/m)\n",
        "    dw[1] = sum(error * X[0]) * (1/m)\n",
        "    dw[2] = sum(error * X[1])* (1/m)\n",
        "    for j in range(m):\n",
        "      w[j] = w[j] - learn_rate * dw[j]\n",
        "\n",
        "    print(f\"Optimized parameters epoch {i}: {w}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Wfpqi0rBAhik"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(X,y,w,0.7,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABXib0D9BDQ4",
        "outputId": "290ba08c-f1a7-43e9-a738-e04da5b7c936"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized parameters epoch 0: [1.07283333 0.66205    0.46298167]\n",
            "Optimized parameters epoch 1: [1.18074016 0.49042136 0.13718248]\n"
          ]
        }
      ]
    }
  ]
}
